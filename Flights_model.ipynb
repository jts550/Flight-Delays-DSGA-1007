{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (7,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "#Load flight data\n",
    "flights_1 = pd.read_csv('flights.csv', header=0, sep=',')\n",
    "\n",
    "#load airline data\n",
    "airlines = pd.read_csv('airlines.csv', header=0, sep=',')\n",
    "\n",
    "\n",
    "#merge airline data to flight data\n",
    "flights_2 = pd.merge(flights_1, \n",
    "                     airlines, \n",
    "                     how='left', \n",
    "                     left_on='AIRLINE',\n",
    "                     right_on='IATA_CODE')\n",
    "\n",
    "\n",
    "#load airport data\n",
    "airports = pd.read_csv('airports.csv', header=0, sep=',')\n",
    "\n",
    "#merge airport data to flight data\n",
    "flights_3 = pd.merge(flights_2, \n",
    "                     airports, \n",
    "                     how='left', \n",
    "                     left_on='ORIGIN_AIRPORT', \n",
    "                     right_on='IATA_CODE')\n",
    "\n",
    "\n",
    "flights_4 = pd.merge(flights_3, \n",
    "                     airports, \n",
    "                     how='left', \n",
    "                     left_on='DESTINATION_AIRPORT', \n",
    "                     right_on='IATA_CODE', \n",
    "                     suffixes=('_ORIGIN', '_DESTINATION'))\n",
    "\n",
    "#drop duplicate columns from merging\n",
    "flights = flights_4.drop(['IATA_CODE_y','IATA_CODE_x','IATA_CODE'],axis = 1)\n",
    "\n",
    "#rename columns changed in merging\n",
    "flights = flights.rename(columns = {'AIRLINE_x':'AIRLINE_CODE', 'AIRLINE_y':'AIRLINE_NAME'})\n",
    "\n",
    "#replace NaN with 0\n",
    "flights = flights.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#makes hourly bins for departure and arrival times format \"0000\" \n",
    "hour_bins = np.arange(0,2500,100)\n",
    "Hours = np.arange(0,2400,100)\n",
    "\n",
    "time_columns = ['SCHEDULED_DEPARTURE','DEPARTURE_TIME', 'SCHEDULED_TIME', 'SCHEDULED_ARRIVAL', 'ARRIVAL_TIME']\n",
    "\n",
    "for i in time_columns:\n",
    "    flights[i.lower()] = pd.cut(flights[i], \n",
    "                                        hour_bins, \n",
    "                                        labels=Hours)\n",
    "    if i[0] == 'S':\n",
    "        flights[i + '_SINE'] = flights[i].apply(lambda x: np.sin(2*np.pi*x/2400))\n",
    "        flights[i + '_COSINE'] = flights[i].apply(lambda x: np.cos(2*np.pi*x/2400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weather data processing\n",
    "directory = os.getcwd() + os.sep + 'weather_data' + os.sep\n",
    "file_after = '_201501010000_201601010000.txt'\n",
    "all_weather_list = []\n",
    "\n",
    "for IATA in airports['IATA_CODE'].unique():\n",
    "    airport_weather = pd.read_csv(directory + IATA + file_after, skiprows = 5,\n",
    "                                 na_values = 'M', parse_dates = ['valid'])\n",
    "    \n",
    "    airport_weather['IATA'] = IATA\n",
    "    airport_weather['MONTH'] = airport_weather['valid'].apply(lambda x: x.month).astype(int)\n",
    "    airport_weather['DAY'] = airport_weather['valid'].apply(lambda x: x.day).astype(int)\n",
    "    airport_weather['HOUR'] = airport_weather['valid'].apply(lambda x: x.hour * 100).astype(int)\n",
    "    airport_weather['hour'] = pd.cut(airport_weather['HOUR'], hour_bins, labels = Hours, include_lowest = True)\n",
    "\n",
    "    airport_weather.drop(labels = ['station',' mslp',' skyc2',' skyc3',' skyc4',' skyl1',\n",
    "                                   ' skyl2',' skyl3',' skyl4',' presentwx',' metar'],\n",
    "                                     axis = 1, inplace = True)\n",
    "    #Take the first instance when there are multiple overlapping points for one interval\n",
    "    airport_weather.drop_duplicates(['MONTH','DAY','hour'], inplace = True)\n",
    "    all_weather_list.append(airport_weather)\n",
    "\n",
    "weather = pd.concat(all_weather_list)\n",
    "\n",
    "#sub NA values\n",
    "weather[' gust'].fillna(0, inplace = True)\n",
    "for col in ['tmpf',' dwpf',' relh',' drct',' sknt',' p01i',' alti',' vsby']:\n",
    "    weather[col].fillna(-1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Merge the weather data to the relevant airports\n",
    "flights_weather = pd.merge(flights,\n",
    "                           weather,\n",
    "                           how = 'left',\n",
    "                           left_on = ['ORIGIN_AIRPORT', 'MONTH', 'DAY','departure_time'],\n",
    "                           right_on = ['IATA', 'MONTH', 'DAY', 'hour'])\n",
    "\n",
    "flights_weather = pd.merge(flights_weather,\n",
    "                           weather,\n",
    "                           how = 'left',\n",
    "                           left_on = ['DESTINATION_AIRPORT', 'MONTH', 'DAY','departure_time'],\n",
    "                           right_on = ['IATA', 'MONTH', 'DAY', 'hour'],\n",
    "                           suffixes = ('_ORIGIN', '_DESTINATION'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "subset = flights[['YEAR', 'MONTH', 'DAY', 'DAY_OF_WEEK','SCHEDULED_TIME', 'DISTANCE', 'LATITUDE_ORIGIN', 'LONGITUDE_ORIGIN',\n",
    "       'LATITUDE_DESTINATION', 'LONGITUDE_DESTINATION', 'SCHEDULED_DEPARTURE_SINE', 'SCHEDULED_DEPARTURE_COSINE',\n",
    "            'SCHEDULED_ARRIVAL_SINE', 'SCHEDULED_ARRIVAL_COSINE','CANCELLED']]\n",
    "\n",
    "weather_subset = flights_weather[['YEAR', 'MONTH', 'DAY', 'DAY_OF_WEEK','SCHEDULED_TIME', 'DISTANCE', 'LATITUDE_ORIGIN', 'LONGITUDE_ORIGIN',\n",
    "       'LATITUDE_DESTINATION', 'LONGITUDE_DESTINATION', 'SCHEDULED_DEPARTURE_SINE', 'SCHEDULED_DEPARTURE_COSINE',\n",
    "            'SCHEDULED_ARRIVAL_SINE', 'SCHEDULED_ARRIVAL_COSINE','tmpf_ORIGIN',' dwpf_ORIGIN',' relh_ORIGIN',' drct_ORIGIN',\n",
    "            ' sknt_ORIGIN',' p01i_ORIGIN',' alti_ORIGIN',' vsby_ORIGIN','tmpf_DESTINATION',' dwpf_DESTINATION',\n",
    "            ' relh_DESTINATION',' drct_DESTINATION',' sknt_DESTINATION',' p01i_DESTINATION',' alti_DESTINATION',' vsby_DESTINATION', 'CANCELLED']]\n",
    "\n",
    "weather_subset = weather_subset.dropna()\n",
    "\n",
    "X = subset.drop('CANCELLED', axis = 1)\n",
    "X_weather = weather_subset.drop('CANCELLED', axis = 1)\n",
    "\n",
    "Y = subset['CANCELLED']\n",
    "Y_weather = weather_subset['CANCELLED']\n",
    "\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, \n",
    "#                                   test_size=0.25, random_state=10)\n",
    "\n",
    "#X_w_train,X_w_test,Y_w_train,Y_w_test = train_test_split(X_weather,Y_weather,\n",
    "#                                       test_size = 0.25, random_state = 10)\n",
    "\n",
    "kfolds = KFold(X.shape[0], n_folds = 5)\n",
    "kfolds_weather = KFold(X_weather.shape[0], n_folds = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=sklearn.cross_validation.KFold(n=5159515, n_folds=5, shuffle=False, random_state=None),\n",
       "       error_score='raise',\n",
       "       estimator=Pipeline(steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('lr', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'lr__C': [0.001, 0.01, 0.1, 1, 10, 100], 'lr__penalty': ['l1', 'l2']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "\n",
    "steps = [('scaler', StandardScaler()),\n",
    "        ('lr',LogisticRegression())]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "parameters = {'lr__C' : [10**i for i in range(-3,3)],\n",
    "             'lr__penalty': ['l1','l2']}\n",
    "\n",
    "LR_grid_search = GridSearchCV(pipeline, param_grid = parameters, cv = kfolds, scoring = 'roc_auc')\n",
    "LR_grid_search.fit(X, Y)\n",
    "\n",
    "\n",
    "LR_weather_grid_search = GridSearchCV(pipeline, param_grid = parameters, cv = kfolds_weather, scoring = 'roc_auc')\n",
    "LR_weather_grid_search.fit(X_weather, Y_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV AUC = 0.621\n",
      "Weather Data:\n",
      "Best CV AUC = 0.654\n"
     ]
    }
   ],
   "source": [
    "print(\"Best CV AUC = %.3f\" % LR_grid_search.best_score_)\n",
    "\n",
    "print(\"Weather Data:\")\n",
    "print(\"Best CV AUC = %.3f\" % LR_weather_grid_search.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
